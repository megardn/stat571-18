---
title: "Predicting readmission probability for diabetes inpatients"
author: "Modern Data Mining"
date: ' '
output:
  pdf_document:
    toc: yes
    toc_depth: '4'
  html_document:
    code_folding: show
    highlight: haddock
    theme: lumen
    toc: yes
    toc_depth: 4
    toc_float: yes
  word_document:
    toc: yes
    toc_depth: '4'
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.width = 7, fig.height = 4)
if(!require("pacman")) install.packages("pacman")
pacman::p_load(dplyr, ggplot2, glmnet, car, data.table, skimr, GGally, ggpubr, tidyr, bestglm)   #add your packages here
```




# Instructions

* This is a project. Well organized and well presented write-up is one major motivation here. Please see the section on `Write up` for details. 
* There is no single correct answer.  
* The entire write up should not be more than **5** pages. All the R-codes should be hidden. Any R-output used should be formatted neatly. You may put all supporting documents, graphics, or other exhibits into an Appendix, which is not counted in the 5 page limit.


# Introduction

## Background

Diabetes is a chronic medical condition affecting millions of Americans, but if managed well, with good diet, exercise and medication, patients can lead relatively normal lives. However, if improperly managed, diabetes can lead to patients being continuously admitted and readmitted to hospitals. Readmissions are especially serious - they represent a failure of the health system to provide adequate support to the patient and are extremely costly to the system. As a result, the Centers for Medicare and Medicaid Services announced in 2012 that they would no longer reimburse hospitals for services rendered if a patient was readmitted with complications within 30 days of discharge.

Given these policy changes, being able to identify and predict those patients most at risk for costly readmissions has become a pressing priority for hospital administrators. 

## Goal of the study

In this project, we shall explore how to use the techniques we have learned in order to help better manage diabetes patients who have been admitted to a hospital. Our goal is to avoid patients being readmitted within 30 days of discharge, which reduces costs for the hospital and improves outcomes for patients. If we could identify important factors relating to the chance of a patient being readmitted within 30 days of discharge, effective intervention could be done to reduce the chance of being readmitted. Also if we could predict one's chance being readmitted well, actions can be taken. 

## The data

The original data is from the [Center for Clinical and Translational Research](https://archive.ics.uci.edu/ml/datasets/Diabetes+130-US+hospitals+for+years+1999-2008) at Virginia Commonwealth University. It covers data on diabetes patients across 130 U.S. hospitals from 1999 to 2008. There are over 100,000 unique hospital admissions in this dataset, from ~70,000 unique patients. The data includes demographic elements, such as age, gender, and race, as well as clinical attributes such as tests conducted, emergency/inpatient visits, etc. Refer to the original documentation for more details on the dataset. Three former students Spencer Luster, Matthew Lesser and Mridul Ganesh, brought this data set into the class and did a wonderful final project. We will use a subset processed by the group but with a somewhat different objective.

Data needed (see detailed information below): 

- **`diabetic.data.csv`**
- **`readmission.csv`**

### Characteristics of the Data Set

All observations have five things in common:

1.	They are all hospital admissions
2.	Each patient had some form of diabetes
3.	The patient stayed for between 1 and 14 days.
4.	The patient had laboratory tests performed on him/her.
5.	The patient was given some form of medication during the visit.

The data was collected during a ten-year period from 1999 to 2008. There are over 100,000 unique hospital admissions in the data set, with ~70,000 unique patients. 

### Description of variables

The dataset used covers ~50 different variables to describe every hospital diabetes admission. In this section we give an overview and brief description of the variables in this dataset.

**1) Patient identifiers:** 

a. `encounter_id`: unique identifier for each admission 
b. `patient_nbr`: unique identifier for each patient *Note: potentially non-independent observations, maybe should restrict to one admission per patient?*

**2) Patient Demographics:** 

`race`, `age`, `gender`, `weight` cover the basic demographic information associated with each patient. `Payer_code` is an additional variable that identifies which health insurance (Medicare /Medicaid / Commercial) the patient holds.

**3) Admission and discharge details:** 

a.	`admission_source_id` and `admission_type_id` identify who referred the patient to the hospital (e.g. physician vs. emergency dept.) and what type of admission this was (Emergency vs. Elective vs. Urgent). 
b.	`discharge_disposition_id` indicates where the patient was discharged to after treatment.

**4) Patient Medical History:**

a.	`num_outpatient`: number of outpatient visits by the patient in the year prior to the current encounter
b.	`num_inpatient`: number of inpatient visits by the patient in the year prior to the current encounter
c.	`num_emergency`: number of emergency visits by the patient in the year prior to the current encounter

**5)	Patient admission details:**

a.	`medical_specialty`: the specialty of the physician admitting the patient
b.	`diag_1`, `diag_2`, `diag_3`: ICD9 codes for the primary, secondary and tertiary diagnoses of the patient.  ICD9 are the universal codes that all physicians use to record diagnoses. There are various easy to use tools to lock up what individual codes mean (Wikipedia is pretty decent on its own)
c.	`time_in_hospital`: the patient’s length of stay in the hospital (in days)
d.	`number_diagnoses`: Total no. of diagnosis entered for the patient
e.	`num_lab_procedures`: No. of lab procedures performed in the current encounter
f.	`num_procedures`: No. of non-lab procedures performed in the current encounter
g.	`num_medications`: No. of distinct medications prescribed in the current encounter

**6)	Clinical Results:**

a.	`max_glu_serum`: indicates results of the glucose serum test
b.	`A1Cresult`: indicates results of the A1c test

**7)	Medication Details:**

a.	`diabetesMed`: indicates if any diabetes medication was prescribed 
b.	`change`: indicates if there was a change in diabetes medication
c.	`24 medication variables`: indicate whether the dosage of the medicines was changed in any manner during the encounter

**8)	Readmission indicator:** 

Indicates whether a patient was readmitted after a particular admission. There are 3 levels for this variable: "NO" = no readmission, "< 30" = readmission within 30 days and "> 30" = readmission after more than 30 days. The 30 day distinction is of practical importance to hospitals because federal regulations penalize hospitals for an excessive proportion of such readmissions.

To save your time we are going to use some data sets cleaned by the group. Thus, we provide two datasets:

**`diabetic.data.csv`** is the original data. You may use it for the purpose of summary if you wish. You will see that the original data can’t be used directly for your analysis, yet. *Note: we should probably just skip ahead to using readmission.csv instead of trying to fuss with both?*

**`readmission.csv`** is a cleaned version and they are modified in the following ways:

1) `Payer code`, `weight` and `Medical Specialty` are not included since they have a large number of missing values. 

2) Variables such as `acetohexamide`, `glimepiride.pioglitazone`, `metformin.rosiglitazone`, `metformin.pioglitazone` have little variability, and are as such excluded. This also includes the following variables: `chlorpropamide`, `acetohexamide`, `tolbutamide`, `acarbose`, `miglitor`, `troglitazone`, `tolazamide`, `examide`, `citoglipton`, `glyburide.metformin`, `glipizide.metformin`, and `glimepiride.pioglitazone`.

3) Some categorical variables have been regrouped. For example, `Diag1_mod` keeps some original levels with large number of patients and aggregates other patients as `others`. This process is known as 'binning.'
		
4) The event of interest is **readmitted within < 30 days**. Note that you need to create this response first by regrouping **Readmission indicator**!

## EDA

### Numerical summary 

First, we read in `readmission.csv` as `readmit_data` and provide a numerical summary:

```{r}
readmit_data <- read.csv("readmission.csv", header=T, na.strings= c("?", "None"), stringsAsFactors = T)

#recode encounter_id and patient_nbr as factor
readmit_data <- readmit_data %>% mutate(encounter_id = as.factor(encounter_id),
                                        patient_nbr = as.factor(patient_nbr),
                                        readmit_30 = as.factor(ifelse(readmitted == '<30', 1, 0)))

# str(readmit_data) 
# summary(readmit_data)
skim(readmit_data)
```

 Note that the `A1Cresult` and `max_glu_serum` variables are dropped since there the majority of rows contain missing values (0.05% and 0.1% non-NA values in `max_glu_serum` and `A1Cresult`, respectively).
 
```{r}
# dropping variables with mostly NAs
readmit_data <- readmit_data %>%
  select(-c(A1Cresult, max_glu_serum))
```

We are also adding a variable encoding the cumulative number of admissions per patient (`nb_admissions`). 

```{r}
readmit_data <- readmit_data %>%
  arrange(patient_nbr, encounter_id) %>%
  group_by(patient_nbr) %>%
  mutate(nb_admissions = rep(seq(n()))) %>%
  ungroup()
  # summarise(total_nb_admissions = n()) # total nb admissions

skim(readmit_data[["nb_admissions"]])

```


## Visual summary

Because logistic regression depends on observations being independent, we subsetted by selecting only one random hospitalization for each individual patient. We will perform further EDA and further modelling on this subsetted sample.

```{r}
#filter unique pt's random hospitalizations
set.seed(100) #seed for reproducibility
readmit_uniq <- readmit_data %>% 
   group_by(patient_nbr) %>%
   sample_n(1)

str(readmit_uniq)
sum(readmit_uniq$readmit_30==1)/nrow(readmit_uniq)

#quick plot to see differences between readmission among all data and unique pt subset
p1 <- ggplot(readmit_data, aes(x=readmitted)) + 
  geom_bar(aes(y = (..count..)/sum(..count..), fill = readmitted)) + 
  ylim(0, 0.75) +
  labs(title = "Readmission in Full Dataset", y="Percent")
p2 <- ggplot(readmit_uniq, aes(x=readmitted)) + 
  geom_bar(aes(y = (..count..)/sum(..count..), fill = readmitted)) + 
  ylim(0, 0.75) +
  labs(title = "Readmission in Random Hosp Subset", y="Percent")
p3 <- ggplot(readmit_data, aes(x = readmit_30)) + 
  geom_bar(aes(y = (..count..)/sum(..count..), fill = readmit_30)) + 
  labs(title = "Readmission within 30 days in Full Hosp Subset", y="Percent")
p4 <- ggplot(readmit_uniq, aes(x = readmit_30)) + 
  geom_bar(aes(y = (..count..)/sum(..count..), fill = readmit_30)) + 
  labs(title = "Readmission within 30 days in Random Hosp Subset", y="Percent")

ggarrange(p1, p2, ncol = 2, common.legend = T)
ggarrange(p3, p4, ncol = 2, common.legend = T)
```

We can observe that:
* around 10% of the full sample is readmitted within 1 month
* around 7% of the latest hospital admission is readmitted within 1 month

Further exploratory visualizations are performed to obtain an initial sense of which variables may play a role in whether patients are readmitted within 30 days or not:

```{r visualizing readmit_30 and other variables}

#DO we want to do this EDA in the subset or full dataset? Maybe keep full dataset and reorder?

# demographic variables - this output is quite ugly, we might want to substitute with individual plots for each demographic factor in relation to readmit_30
# readmit_data %>% 
#   select(readmit_30, race, age_mod, gender) %>% 
#   ggpairs(aes(color = readmit_30))

# plotting gender
readmit_data %>%
  filter(gender == "Female" | gender == "Male") %>%
  ggplot(aes(x = readmit_30)) + 
    geom_bar(aes(y = (..count..)/sum(..count..), fill = readmit_30)) + 
    facet_wrap(~gender) +
    labs(title = "Readmission within 30 days by gender", y="Percent")

# plotting age bins
readmit_data %>%
  ggplot(aes(x = readmit_30)) + 
    geom_bar(aes(y = (..count..)/sum(..count..), fill = readmit_30)) + 
    facet_wrap(~age_mod) +
    labs(title = "Readmission within 30 days by age bins", y="Percent")

# plotting race
readmit_data %>%
  drop_na(race) %>% #drop NAs before plotting - makes sense i think?
  ggplot(aes(x = readmit_30)) + 
    geom_bar(aes(y = (..count..)/sum(..count..), fill = readmit_30)) + 
    facet_wrap(~race) +
    labs(title = "Readmission within 30 days by race", y="Percent")


# plotting medications
readmit_data %>% 
  tidyr::pivot_longer(cols = metformin:insulin, 
               names_to = "Medication",
               values_to = "Trend") %>% 
  ggplot(aes(Trend, Medication, fill = readmit_30)) + 
    geom_bar(aes(y = (..count..)/sum(..count..)), position = "dodge") + 
    facet_wrap(~Medication) +
    labs(title = "Readmission within 30 days by medication trends", y="Percent")

# plotting change in rx
readmit_data %>%
  drop_na(change) %>% #drop NAs before plotting - makes sense i think?
  ggplot(aes(x = readmit_30)) + 
    geom_bar(aes(y = (..count..)/sum(..count..), fill = readmit_30)) + 
    facet_wrap(~change) +
    labs(title = "Readmission within 30 days by change in diabetes", y="Percent")

# could do the same for the remaining factors about diabetes medication, discharge, admission

# numerical variables
readmit_data %>% 
  select(readmit_30, time_in_hospital, num_lab_procedures, num_procedures, num_medications, 
         number_outpatient, number_inpatient, number_emergency, nb_admissions, number_diagnoses) %>% 
  ggpairs(aes(color = readmit_30))
```

Based on the above plots, readmissions within 30 days may potentially occur more frequently in 60-70 year old patients and in Caucasian patients, although it should be noted that the sample contains an overrepresentation of the Caucasian population in general. Numerical variables do not show clear differences between patients who are and aren't readmitted within 30 days.  

# Research approach

From the *Goals* section above, your study should respond to the following:

## Analyses suggested

1) Identify important factors that capture the chance of a readmission within 30 days. 

We first split the data into `data.train`(60%), `data.test` (20%) and `data.val` (20%). 

```{r}
# Split the data
N <- length(readmit_rand$patient_nbr)
n1 <- floor(.6*N)
n2 <- floor(.2*N)

set.seed(10)

# Split data to three portions of .6, .2 and .2 of data size N
idx_train <- sample(N, n1)
idx_no_train <- (which(! seq(1:N) %in% idx_train))
idx_test <- sample(idx_no_train, n2)
idx_val <- which(! idx_no_train %in% idx_test)
data.train <- as.data.frame(readmit_rand[idx_train,])
data.test <- as.data.frame(readmit_rand[idx_test,])
data.val <- as.data.frame(readmit_rand[idx_val,])
data.train.lasso <- rbind(data.train, data.test)
``` 

To determine which factors play a role in patient readmission < 30 days, we use a group `LASSO` approach (`cv.glmnet()`) where the deviance is minimized. Note that rows with NAs are omitted in this process given that the LASSO function does not tolerate these. We will use the training dataset to build the model and the validation subset to evaluate our final model. Because we are using LASSO to select our predictors, a testing dataset will not be necessary, and so we'll incorporate these data points into the training dataset for this test.

```{r run LASSO}
#remove columns we don't want to include as predictors or y
readmit_mod <- data.train.lasso %>% 
  select(!c(encounter_id, patient_nbr, readmitted)) %>% # removing patient and admission IDs as well as irrelevant readmitted variable
  na.omit() # omitting NAs as LASSO does not accept these (and model.matrix also removes them by default)

# generate matrices for LASSO
Y <- as.matrix(readmit_mod[, "readmit_30"]) # extract Y and transform to matrix for LASSO to work
X <- model.matrix(readmit_30 ~., data = readmit_mod)[, -1]  # for each factor: num of levels -1

set.seed(100)  # seed for reproducibility 

# run LASSO
fit.readmit.cv <- cv.glmnet(X, Y,  alpha = 1, family = "binomial", nfolds = 10, type.measure = "deviance")

# plotting
plot(fit.readmit.cv)

fit.readmit.cv$lambda.1se # use lambda.1se to select the smaller model
coef.1se <- coef(fit.readmit.cv, s = "lambda.1se") # get coefficients
coef.1se <- coef.1se[which(coef.1se != 0),] # show variables with non-zero coefficients
var.1se <- rownames(as.matrix(coef.1se))[-1] # output variable names without interceptt
var.1se
```

Try running with gLASSO. If you create dummy variables encoding each factor variable, this will keep all factor levels together; seems like a lot of work circle back to this!


Now we use the predictors identified to build our model on `data.train`.

```{r LASSO model}
# let's first select the variables identified through LASSO - for now dropping factor levels and readding full variable
var.1se <- var.1se[-grep("disch_disp_modified|age_mod", var.1se)] # remove factor levels
var.1se <- append(var.1se, c("disch_disp_modified", "age_mod")) # replace levels with full factors
data.train.m <- data.train %>%
  select(c(var.1se, "readmit_30"))

# fit glm with LASSO-identified variables
fit.logit.1 <- glm(readmit_30 ~ ., family = binomial, data = data.train.m) # not sure if we should keep the full data or the readmit_mod without NAs? - think we should keep the NAs in

# check significance of variables
Anova(fit.logit.1)
```

All variables are significant! It seems based on our data that the time spent in the hospital, number of previous inpatient admissions, number of diagnoses, where a patient is discharged to after treatment, and age are significant predictors of an individual's chances of readmission within 30 days. This makes sense because ...

2) For the purpose of classification, propose a model that can be used to predict whether a patient will be a readmit within 30 days. Justify your choice. Hint: use a decision criterion, such as AUC, to choose among a few candidate models.

We'll build another model using bestglm to test against our LASSO model. Since bestglm accepts an upper limit of 15 predictors, we'll subset the training data to 15 predictors (including factor levels) based on our EDA and a prior knowledge: *note - originally used LASSO outputs as starting point but then the model was super small and very redundant*

```{r bestglm}
# mod data.train
data.train.m <- data.train %>% 
  select(c("readmit_30", "race", "gender", "age_mod")) %>% #, "num_medications", "change", "number_diagnoses" "disch_disp_modified", "adm_typ_mod", "diag1_mod"
  na.omit() # omitting NAs (model.matrix also removes them by default)

# Get the design matrix without 1's and HD
Xy_design <- model.matrix(readmit_30 ~.+0, data.train.m) #+0 -> no intercept, gets rid of first col with 1s
# Attach y as the last column.
Xy <- data.frame(Xy_design, data.train.m$readmit_30)   
fit.glm.1 <- bestglm(Xy, family = binomial, method = "forward", IC="AIC") #using forward selection for efficiency
names(fit.glm.1) # fit.all$Subsets to list best submodels
```

Compare bestglm and LASSO models on AUC/ROC, pick sensitivity threshold -> prediction

3) Based on a quick and somewhat arbitrary guess, we estimate **it costs twice as much** to mislabel a readmission than it does to mislabel a non-readmission. Based on this risk ratio, propose a specific classification rule to minimize the cost. If you find any information that could provide a better cost estimate, please justify it in your write-up and use the better estimate in your answer.

Bayes on final model.

Suggestion: You may use any of the methods covered so far in parts 1) and 2), and they need not be the same. Also keep in mind that a training/testing data split may be necessary. 

4) We suggest you to split the data first to Training/Testing/Validation data:

- Use training/testing data to land a final model (If you only use LASSO to land a final model, we will not need testing data since all the decisions are made with cross-validations.)

- *Evaluate the final model with the validation data to give an honest assessment of your final model*. 

# The write up

As you all know, it is very important to present your findings well. To achieve the best possible results you need to understand your audience. 

Your target audience is a manager within the hospital organization. They hold an MBA, are familiar with medical terminology (though you do not need any previous medical knowledge), and have gone through a similar course to our Modern Data Mining with someone like your professor. You can assume thus some level of technical familiarity, but should not let the paper be bogged down with code or other difficult to understand output.

Note then that the most important elements of your report are the clarity of your analysis and the quality of your proposals. 

A suggested outline of the report would include the following components: 

1) Executive Summary

* This section should be accessible by people with very little statistical background (avoid using technical words and no direct R output is allowed)
* Give a background of the study. You may check the original website or other sources to fill in some details, such as to why the questions we address here are important. 
* A quick summary about the data.
* Methods used and the main findings.
* You may use clearly labelled and explained visualizations.
* Issues, concerns, limitations of the conclusions. This is an especially important section to be honest in - we might be Penn students, but we are statisticians today.

2) Detailed process of the analysis

i) Data Summary /EDA

* Nature of the data, origin
* Necessary quantitative and graphical summaries
* Are there any problems with the data?
* Which variables are considered as input 
	
ii) Analyses

* Various appropriate statistical methods: e.g. glmnet 
* Comparisons various models
* Final model(s)

iii) Conclusion

* Summarize results and the final model
* Final recommendations

Maintain a good descriptive flow in the text of your report. Use Appendices to display lengthy output. 

iii) Appendix
	
* Any thing necessary to keep but for which you don’t want them to be in the main report.


<!-- # Collaboration -->

<!-- This is an **individual** assignment. We will only allow private Piazza posts for questions. If there are questions that are generally useful, we will release that information. -->