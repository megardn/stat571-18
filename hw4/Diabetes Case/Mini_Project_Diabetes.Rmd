---
title: "Predicting readmission probability for diabetes inpatients,  HW4 GROUP 18"
author:
- Diego G. Davila
- Margaret Gardner
- Joelle Bagautdinova
date: 'Due before midnight, March 20'
output:
  pdf_document:
    toc: yes
    toc_depth: '4'
  html_document:
    code_folding: show
    highlight: haddock
    theme: lumen
    toc: yes
    toc_depth: 4
    toc_float: yes
  word_document:
    toc: yes
    toc_depth: '4'
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.width = 7, fig.height = 4)
if(!require("pacman")) install.packages("pacman")
pacman::p_load(dplyr, ggplot2, glmnet, car, data.table, skimr, GGally, ggpubr, pROC)   #add your packages here
```




# Instructions

* This is a project. Well organized and well presented write-up is one major motivation here. Please see the section on `Write up` for details. 
* There is no single correct answer.  
* The entire write up should not be more than **5** pages. All the R-codes should be hidden. Any R-output used should be formatted neatly. You may put all supporting documents, graphics, or other exhibits into an Appendix, which is not counted in the 5 page limit.


# Introduction

## Background

Diabetes is a chronic medical condition affecting millions of Americans, but if managed well, with good diet, exercise and medication, patients can lead relatively normal lives. However, if improperly managed, diabetes can lead to patients being continuously admitted and readmitted to hospitals. Readmissions are especially serious - they represent a failure of the health system to provide adequate support to the patient and are extremely costly to the system. As a result, the Centers for Medicare and Medicaid Services announced in 2012 that they would no longer reimburse hospitals for services rendered if a patient was readmitted with complications within 30 days of discharge.

Given these policy changes, being able to identify and predict those patients most at risk for costly readmissions has become a pressing priority for hospital administrators. 

## Goal of the study

In this project, we shall explore how to use the techniques we have learned in order to help better manage diabetes patients who have been admitted to a hospital. Our goal is to avoid patients being readmitted within 30 days of discharge, which reduces costs for the hospital and improves outcomes for patients. If we could identify important factors relating to the chance of a patient being readmitted within 30 days of discharge, effective intervention could be done to reduce the chance of being readmitted. Also if we could predict one's chance being readmitted well, actions can be taken. 

## The data

The original data is from the [Center for Clinical and Translational Research](https://archive.ics.uci.edu/ml/datasets/Diabetes+130-US+hospitals+for+years+1999-2008) at Virginia Commonwealth University. It covers data on diabetes patients across 130 U.S. hospitals from 1999 to 2008. There are over 100,000 unique hospital admissions in this dataset, from ~70,000 unique patients. The data includes demographic elements, such as age, gender, and race, as well as clinical attributes such as tests conducted, emergency/inpatient visits, etc. Refer to the original documentation for more details on the dataset. Three former students Spencer Luster, Matthew Lesser and Mridul Ganesh, brought this data set into the class and did a wonderful final project. We will use a subset processed by the group but with a somewhat different objective.

Data needed (see detailed information below): 

- **`diabetic.data.csv`**
- **`readmission.csv`**

### Characteristics of the Data Set

All observations have five things in common:

1.	They are all hospital admissions
2.	Each patient had some form of diabetes
3.	The patient stayed for between 1 and 14 days.
4.	The patient had laboratory tests performed on him/her.
5.	The patient was given some form of medication during the visit.

The data was collected during a ten-year period from 1999 to 2008. There are over 100,000 unique hospital admissions in the data set, with ~70,000 unique patients. 

### Description of variables

The dataset used covers ~50 different variables to describe every hospital diabetes admission. In this section we give an overview and brief description of the variables in this dataset.

**1) Patient identifiers:** 

a. `encounter_id`: unique identifier for each admission 
b. `patient_nbr`: unique identifier for each patient *Note: potentially non-independent observations, maybe should restrict to one admission per patient?*

**2) Patient Demographics:** 

`race`, `age`, `gender`, `weight` cover the basic demographic information associated with each patient. `Payer_code` is an additional variable that identifies which health insurance (Medicare /Medicaid / Commercial) the patient holds.

**3) Admission and discharge details:** 

a.	`admission_source_id` and `admission_type_id` identify who referred the patient to the hospital (e.g. physician vs. emergency dept.) and what type of admission this was (Emergency vs. Elective vs. Urgent). 
b.	`discharge_disposition_id` indicates where the patient was discharged to after treatment.

**4) Patient Medical History:**

a.	`num_outpatient`: number of outpatient visits by the patient in the year prior to the current encounter
b.	`num_inpatient`: number of inpatient visits by the patient in the year prior to the current encounter
c.	`num_emergency`: number of emergency visits by the patient in the year prior to the current encounter

**5)	Patient admission details:**

a.	`medical_specialty`: the specialty of the physician admitting the patient
b.	`diag_1`, `diag_2`, `diag_3`: ICD9 codes for the primary, secondary and tertiary diagnoses of the patient.  ICD9 are the universal codes that all physicians use to record diagnoses. There are various easy to use tools to lock up what individual codes mean (Wikipedia is pretty decent on its own)
c.	`time_in_hospital`: the patient’s length of stay in the hospital (in days)
d.	`number_diagnoses`: Total no. of diagnosis entered for the patient
e.	`num_lab_procedures`: No. of lab procedures performed in the current encounter
f.	`num_procedures`: No. of non-lab procedures performed in the current encounter
g.	`num_medications`: No. of distinct medications prescribed in the current encounter

**6)	Clinical Results:**

a.	`max_glu_serum`: indicates results of the glucose serum test
b.	`A1Cresult`: indicates results of the A1c test

**7)	Medication Details:**

a.	`diabetesMed`: indicates if any diabetes medication was prescribed 
b.	`change`: indicates if there was a change in diabetes medication
c.	`24 medication variables`: indicate whether the dosage of the medicines was changed in any manner during the encounter

**8)	Readmission indicator:** 

Indicates whether a patient was readmitted after a particular admission. There are 3 levels for this variable: "NO" = no readmission, "< 30" = readmission within 30 days and "> 30" = readmission after more than 30 days. The 30 day distinction is of practical importance to hospitals because federal regulations penalize hospitals for an excessive proportion of such readmissions.

To save your time we are going to use some data sets cleaned by the group. Thus, we provide two datasets:

**`diabetic.data.csv`** is the original data. You may use it for the purpose of summary if you wish. You will see that the original data can’t be used directly for your analysis, yet. *Note: we should probably just skip ahead to using readmission.csv instead of trying to fuss with both? J: agreed let's not use the original data*

**`readmission.csv`** is a cleaned version and they are modified in the following ways:

1) `Payer code`, `weight` and `Medical Specialty` are not included since they have a large number of missing values. 

2) Variables such as `acetohexamide`, `glimepiride.pioglitazone`, `metformin.rosiglitazone`, `metformin.pioglitazone` have little variability, and are as such excluded. This also includes the following variables: `chlorpropamide`, `acetohexamide`, `tolbutamide`, `acarbose`, `miglitor`, `troglitazone`, `tolazamide`, `examide`, `citoglipton`, `glyburide.metformin`, `glipizide.metformin`, and `glimepiride.pioglitazone`.

3) Some categorical variables have been regrouped. For example, `Diag1_mod` keeps some original levels with large number of patients and aggregates other patients as `others`. This process is known as 'binning.'
		
4) The event of interest is **readmitted within < 30 days**. Note that you need to create this response first by regrouping **Readmission indicator**!

## EDA

### Numerical summary 

First, we read in `readmission.csv` as `readmit_data` and provide a numerical summary:


```{r}
readmit_data <- read.csv("readmission.csv", header=T, na.strings= c("?", "None"), stringsAsFactors = T)

#recode encounter_id and patient_nbr as factor
readmit_data <- readmit_data %>% mutate(encounter_id = as.factor(encounter_id),
                                        patient_nbr = as.factor(patient_nbr),
                                        readmit_30 = as.factor(ifelse(readmitted == '<30', 1, 0))) #code new response var readmission indicator - tbh not sure if this should be factor - J: yep I think factor makes sense 

# str(readmit_data) 
# summary(readmit_data)
skim(readmit_data)
```

 Note that the `A1Cresult` and `max_glu_serum` variables are dropped since there the majority of rows contain missing values (0.05% and 0.1% non-NA values in `max_glu_serum` and `A1Cresult`, respectively).
 
```{r}
# dropping variables with mostly NAs
readmit_data <- readmit_data %>%
  select(-c(A1Cresult, max_glu_serum))
```

We are also adding a variable encoding the cumulative number of admissions per patient (`nb_admissions`). 

```{r}
readmit_data <- readmit_data %>%
  arrange(patient_nbr, encounter_id) %>%
  group_by(patient_nbr) %>%
  mutate(nb_admissions = rep(seq(n()))) %>%
  ungroup()
  # summarise(total_nb_admissions = n()) # total nb admissions

skim(readmit_data[["nb_admissions"]])

```


Remove duplicate patient IDs such that we only have the last inpatient admission for each subject. *Note: Seems to make sense to take the latest hospitalization, since it's most "up-to-date" but we could take first instead? Either way it'll probably skew whether pts are readmitted or not, or we could try to filter randomly. J: hmm I after looking at the data it seems like every row is sort of a new event (i.e., tracks readmission following that hospitalization event), so maybe it makes sense to keep them all?*

## Visual summary

```{r}
readmit_uniq <- readmit_data %>% 
  arrange(-number_inpatient) %>%
  filter(!duplicated(patient_nbr))

str(readmit_uniq)

#quick plot to see differences between readmission among all data and unique pt subset
p1 <- ggplot(readmit_data, aes(x=readmitted)) + 
  geom_bar(aes(y = (..count..)/sum(..count..), fill = readmitted)) + 
  ylim(0, 0.75) +
  labs(title = "Readmission in Full Dataset", y="Percent")
p2 <- ggplot(readmit_uniq, aes(x=readmitted)) + 
  geom_bar(aes(y = (..count..)/sum(..count..), fill = readmitted)) + 
  ylim(0, 0.75) +
  labs(title = "Readmission in Latest Hosp Subset", y="Percent")
p3 <- ggplot(readmit_data, aes(x = readmit_30)) + 
  geom_bar(aes(y = (..count..)/sum(..count..), fill = readmit_30)) + 
  labs(title = "Readmission < or > 30 days in Full Hosp Subset", y="Percent")
p4 <- ggplot(readmit_uniq, aes(x = readmit_30)) + 
  geom_bar(aes(y = (..count..)/sum(..count..), fill = readmit_30)) + 
  labs(title = "Readmission < or > 30 days in Latest Hosp Subset", y="Percent")

ggarrange(p1, p2, ncol = 2, common.legend = T)
ggarrange(p3, p4, ncol = 2, common.legend = T)
```

We can observe that:
* around 10% of the full sample is readmitted within 1 month
* around 3% of the latest hospital admission is readmitted within 1 month

Further exploratory visualizations are performed to obtain an initial sense of which variables may play a role in whether patients are readmitted within 30 days or not:

```{r visualizing readmit_30 and other variables}

# demographic variables - this output is quite ugly, we might want to substitute with individual plots for each demographic factor in relation to readmit_30
# readmit_data %>% 
#   select(readmit_30, race, age_mod, gender) %>% 
#   ggpairs(aes(color = readmit_30))

# plotting gender
readmit_data %>%
  filter(gender == "Female" | gender == "Male") %>%
  ggplot(aes(x = readmit_30)) + 
    geom_bar(aes(y = (..count..)/sum(..count..), fill = readmit_30)) + 
    facet_wrap(~gender) +
    labs(title = "Readmission < or > 30 days by gender", y="Percent")

# plotting age bins
readmit_data %>%
  ggplot(aes(x = readmit_30)) + 
    geom_bar(aes(y = (..count..)/sum(..count..), fill = readmit_30)) + 
    facet_wrap(~age_mod) +
    labs(title = "Readmission < or > 30 days by age bins", y="Percent")

# plotting race
readmit_data %>%
  ggplot(aes(x = readmit_30)) + 
    geom_bar(aes(y = (..count..)/sum(..count..), fill = readmit_30)) + 
    facet_wrap(~race) +
    labs(title = "Readmission < or > 30 days by race", y="Percent")


# plotting medications
readmit_data %>% 
  tidyr::pivot_longer(cols = metformin:insulin, 
               names_to = "Medication",
               values_to = "Trend") %>% 
  ggplot(aes(Trend, Medication, fill = readmit_30)) + 
    geom_bar(aes(y = (..count..)/sum(..count..)), position = "dodge") + 
    facet_wrap(~Medication) +
    labs(title = "Readmission < or > 30 days by medication trends", y="Percent")

# could do the same for the remaining factors about diabetes medication, discharge, admission

# numerical variables
readmit_data %>% 
  select(readmit_30, time_in_hospital, num_lab_procedures, num_procedures, num_medications, 
         number_outpatient, number_inpatient, number_emergency, nb_admissions, number_diagnoses) %>% 
  ggpairs(aes(color = readmit_30))
```
Based on the above plots, readmissions within 30 days may potentially occur more frequently in 60-70 year old patients and in Caucasian patients, although it should be noted that the sample contains an overrepresentation of the Caucasian population in general. Numerical variables do not show clear differences between patients admitted < or > 30 days.  


# Research approach

From the *Goals* section above, your study should respond to the following:

## Analyses suggested

1) Identify important factors that capture the chance of a readmission within 30 days. 

The set of available predictors is not limited to the raw variables in the data set. You may engineer any factors using the data, that you think will improve your model's quality.

To determine which factors play a role in patient readmission < 30 days, we use a `LASSO` approach (`cv.glmnet()`) where the deviance is minimized. Note that rows with NAs are omitted in this process given that the LASSO function does not tolerate these.  

```{r run LASSO}

#remove columns we don't want to include as predictors or y
readmit_mod <- readmit_data %>% 
  select(!c(encounter_id, patient_nbr, readmitted)) %>% # removing patient and admission IDs as well as irrelevant readmitted variable
  na.omit() # omitting NAs as LASSO does not accept these (and model.matrix also removes them by default)

# generate matrices for LASSO
Y <- as.matrix(readmit_mod[, "readmit_30"]) # extract Y and transform to matrix for LASSO to work
X <- model.matrix(readmit_30 ~., data = readmit_mod)[, -1]  # for each factor: num of levels -1

set.seed(100)  # seed for reproducibility 

# run LASSO
fit.readmit.cv <- cv.glmnet(X, Y,  alpha = 1, family = "binomial", nfolds = 10, type.measure = "deviance")

# plotting
plot(fit.readmit.cv)

fit.readmit.cv$lambda.1se # use lambda.1se to select the smaller model
coef.1se <- coef(fit.readmit.cv, s = "lambda.1se") # get coefficients
coef.1se <- coef.1se[which(coef.1se != 0),] # show variables with non-zero coefficients

# output variable names
coef.1se <- rownames(as.matrix(coef.1se))[-1] 
coef.1se
```

Next, we use `glm()` to generate the logistic regression model based on the above selected variables. 

```{r run glm}

# let's first select the variables identified through LASSO
coef.1se <- coef(fit.readmit.cv, s="lambda.1se")  #s lambda value
coef.1se <- coef.1se[which(coef.1se != 0),] # get the non-zero coefficients
var.1se <- rownames(as.matrix(coef.1se))[-1] # output the variable names without intercept
var.1se <- var.1se[-grep("diabetesMed|diag1_mod|disch_disp_modified|insulin", var.1se)] # remove factor levels (full factors are re-added below)
readmit_mod_sub <-  readmit_mod %>%
  select(c("diabetesMed", "diag1_mod", "disch_disp_modified", "insulin", "readmit_30", var.1se)) # get a subset with response and LASSO output

# maybe we should consider splitting data here and only test model fit on part of the data? 

# fit glm with LASSO-identified variables
fit.logit.1 <- glm(readmit_30 ~. , family = binomial, data = readmit_mod_sub) # not sure if we should keep the full data or the readmit_mod without NAs?

# check significance of variables
Anova(fit.logit.1)

```

2) For the purpose of classification, propose a model that can be used to predict whether a patient will be a readmit within 30 days. Justify your choice. Hint: use a decision criterion, such as AUC, to choose among a few candidate models.

The model above indicates that time_in_hospital may potentially not have such an important role in classifying patient readmission < or > 30 days. Let's try removing this variable from the model. To determine the best model fit, we use a ROC curve comparison and the Chi-square test from `anova()`. 

```{r choosing the best model}

# create a reduced model fit without time_in_hospital
fit.logit.2 <- update(fit.logit.1, .~. -time_in_hospital) 

# ROC curve approach
fit.logit.1.ROC <- roc(readmit_mod_sub$readmit_30, fit.logit.1$fitted) # getting model 1 ROC 
fit.logit.2.ROC <- roc(readmit_mod_sub$readmit_30, fit.logit.2$fitted) # getting model 2 ROC 

# plotting both ROC curves
plot(1 - fit.logit.1.ROC$specificities, fit.logit.1.ROC$sensitivities, col = "red", lwd = 3, type = "l", # plotting the first curve
     xlab = "False Positive", 
     ylab = "Sensitivity")

lines(1 - fit.logit.2.ROC$specificities, fit.logit.2.ROC$sensitivities, col="blue", lwd=3) # plotting the second curve 

legend("bottomright",
       c(paste0("fit1 AUC=", round(fit.logit.1.ROC$auc,2)), 
         paste0("fit2 AUC=", round(fit.logit.2.ROC$auc, 2)), 
       col=c("red", "blue"),
       lty = 1)
       
       
# compare full and reduced models
anova(fit.logit.2, fit.logit.1, test = "Chisq")

```

While the ROC curves are practically identical, based on the Chi-squared test we cannot reject the null hypothesis that the reduced model is sufficient in explaining the data (`p = 0.06`) (right?). Thus, we will keep the reduced model excluding `time_in_hospital`.


```{r}
# check significance of variables in reduced model
Anova(fit.logit.2)

# more detailed summary
summary(fit.logit.2)

```

All the variables are now significant. Based on the above analysis, readmission within 30 days is more likely for patients with diabetes medication, when they have been discharged to other locations types than home without health services (?), when they receive more medications and when they've visited the hospital more frequently (outpatient, inpatient, emergency and prior number of admissions to the hospital). **Does this interpretation make sense?**


3) Based on a quick and somewhat arbitrary guess, we estimate **it costs twice as much** to mislabel a readmission than it does to mislabel a non-readmission. Based on this risk ratio, propose a specific classification rule to minimize the cost. If you find any information that could provide a better cost estimate, please justify it in your write-up and use the better estimate in your answer.

Suggestion: You may use any of the methods covered so far in parts 1) and 2), and they need not be the same. Also keep in mind that a training/testing data split may be necessary. 

Bayes' rule can be used as a classification rule to minimize the cost according to specific weights. 

```{r Bayes rule}

# Applying Bayes rule
fit.logit.2.bayes <- as.factor(ifelse(fit.logit.2$fitted > .17, "1", "0")) # not sure if we should use .17 as in the lecture or define it some other way?
MCE.bayes <- (2 * sum(fit.logit.2.bayes[readmit_mod_sub$readmit_30 == "1"] != "1") 
                      + sum(fit.logit.2.bayes[readmit_mod_sub$readmit_30 == "0"] != "0"))/length(readmit_mod_sub$readmit_30)
MCE.bayes

```

4) We suggest you to split the data first to Training/Testing/Validation data:

- Use training/testing data to land a final model (If you only use LASSO to land a final model, we will not need testing data since all the decisions are made with cross-validations.)

- Evaluate the final model with the validation data to give an honest assessment of your final model. 

# The write up

As you all know, it is very important to present your findings well. To achieve the best possible results you need to understand your audience. 

Your target audience is a manager within the hospital organization. They hold an MBA, are familiar with medical terminology (though you do not need any previous medical knowledge), and have gone through a similar course to our Modern Data Mining with someone like your professor. You can assume thus some level of technical familiarity, but should not let the paper be bogged down with code or other difficult to understand output.

Note then that the most important elements of your report are the clarity of your analysis and the quality of your proposals. 

A suggested outline of the report would include the following components: 

1) Executive Summary

* This section should be accessible by people with very little statistical background (avoid using technical words and no direct R output is allowed)
* Give a background of the study. You may check the original website or other sources to fill in some details, such as to why the questions we address here are important. 
* A quick summary about the data.
* Methods used and the main findings.
* You may use clearly labelled and explained visualizations.
* Issues, concerns, limitations of the conclusions. This is an especially important section to be honest in - we might be Penn students, but we are statisticians today.

2) Detailed process of the analysis

i) Data Summary /EDA

* Nature of the data, origin
* Necessary quantitative and graphical summaries
* Are there any problems with the data?
* Which variables are considered as input 
	
ii) Analyses

* Various appropriate statistical methods: e.g. glmnet 
* Comparisons various models
* Final model(s)

iii) Conclusion

* Summarize results and the final model
* Final recommendations

Maintain a good descriptive flow in the text of your report. Use Appendices to display lengthy output. 

iii) Appendix
	
* Any thing necessary to keep but for which you don’t want them to be in the main report.


<!-- # Collaboration -->

<!-- This is an **individual** assignment. We will only allow private Piazza posts for questions. If there are questions that are generally useful, we will release that information. -->