---
title: " Modern Data Mining, HW 1"
author:
- Joelle Bagautdinova
- Diego Davila
- Margaret Gardner
date: 'Due: 11:59PM,  Jan. 30th, 2021'
output:
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: '4'
  html_document:
    code_folding: show
    highlight: haddock
    number_sections: yes
    theme: lumen
    toc: yes
    toc_depth: 4
    toc_float: yes
  word_document:
    toc: yes
    toc_depth: '4'
urlcolor: blue
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, results = "hide", fig.width=8, fig.height=4)
options(scipen = 0, digits = 3)  # controls base R output
# check if you have ISLR package, if not, install it
if(!require('pacman')) {install.packages('pacman')}
pacman::p_load(ISLR, readxl, tidyverse, magrittr, dplyr, ggplot2, haven)
```


\pagebreak

##  Instructions

- **Submit the following files, one submission for each group:**  (1) Rmd file, (2) a compiled PDF or HTML version, and (3) all necessary data files if different from our source data. You may directly edit this .rmd file to add your answers. If you intend to work on the problems separately within your group, compile your answers into one Rmd file before submitting. We encourage that you at least attempt each problem by yourself before working with your teammates. Additionally, ensure that you can 'knit' or compile your Rmd file. It is also likely that you need to configure Rstudio to properly convert files to PDF. [**These instructions**](http://kbroman.org/knitr_knutshell/pages/latex.html#converting-knitrlatex-to-pdf) might be helpful.

- In general, be as concise as possible while giving a fully complete answer to each question. All necessary datasets are available in this homework folder on Canvas. Make sure to document your code with comments (written on separate lines in a code chunk using a hashtag `#` before the comment) so the teaching fellows can follow along. R Markdown is particularly useful because it follows a 'stream of consciousness' approach: as you write code in a code chunk, make sure to explain what you are doing outside of the chunk. 

# Case study 1: Audience Size

## Data preparation

Loading survey data.
``` {r c1 load.mturk, echo=FALSE}
#read data into df from csv and replacing blanks with NA
mturk <- read.csv("data/Survey_results_final.csv", header = TRUE, stringsAsFactors = F, na = "") 
#colnames(mturk)
```

i. Selecting and renaming only specified variables of interest for clarity.

``` {r filt&rename, echo=FALSE}
#write new df filtered to desired columns and rename column headers
radio <- mturk %>% select(Answer.Age, Answer.Gender, Answer.Education, Answer.HouseHoldIncome, Answer.Sirius.Radio, Answer.Wharton.Radio, WorkTimeInSeconds) %>% rename(age = Answer.Age, gender = Answer.Gender, education = Answer.Education, income = Answer.HouseHoldIncome, sirius = Answer.Sirius.Radio, wharton = Answer.Wharton.Radio, worktime = WorkTimeInSeconds)

#visualize data
head(radio, 5)
str(radio)
sum(is.na(radio))
```

ii. Handling missing/wrongly filled values of the selected variables

Generally, data may be wrong or incorrect if participants were confused by the instructions or inattentive to the survey.

Dropping any respondents who are missing answers for listening to Sirius Radio or Wharton radio, since this data won't be usable for our analyses.

``` {r c1 drop.na}
radio <- radio %>% drop_na(sirius) %>% drop_na(wharton) #drop any rows missing sirius/wharton listenership, since that's what we care about most
```

Cleaning age data to ensure data is a continuous numerical. Dropping any datapoints outside the range of 18 to 110 years which are likely erroneous; MTurk requires that workers be at least 18 years old and age above 110 is rare.
``` {r age.correct}
#find variables in age with no numerical component
parse_number(radio$age) 

#replace chr variables identified above with NA and recover entries with both chr & int data via parse_number()
radio <- radio %>% mutate(age = parse_number(age, na="female")) 

#now that age is numeric, find min/max and drop data outside reasonable age range (must be 18+ to work for mturk):
radio %>% summarise(min=min(age, na.rm=T), max=max(age, na.rm=T))
is.na(radio$age) <- which(radio$age < 18 | radio$age >110)
```


Cleaning categorical variables by marking as factors and ordering levels as appropriate for inherently ranked categories (i.e. education, income)
```{r factor.correct}
#converting categorical data to factors:
radio <- radio %>% mutate(gender = as.factor(gender),
          education = as.factor(education),
          income = as.factor(income),
          sirius = as.factor(sirius),
          wharton = as.factor(wharton))
#listing unique levels to make sure all make sense
radio %>% sapply(levels)

#clean up education:
  #replace unselected education values with NA
is.na(radio$education) <- which(radio$education == "select one") 
  #drop the now unused "select one" level
radio$education <-droplevels(radio$education) 
  #reorder
radio$education<- factor(radio$education, levels=c("Less than 12 years; no high school diploma", "High school graduate (or equivalent)", "Some college, no diploma; or Associate’s degree", "Bachelor’s degree or other 4-year degree", "Graduate or professional degree", "Other"))

#reordrer income levels
radio$income<- factor(radio$income, levels=c("Less than $15,000", "$15,000 - $30,000", "$30,000 - $50,000", "$50,000 - $75,000", "$75,000 - $150,000", "Above $150,000"))
```

Check worktime variable to ensure data is reasonable, no changes needed.
``` {r worktime.correct}
#look at worktime - automatically calculated by site and all seem to make sense, no corrections needed
sum(is.na(radio$worktime))
radio %>% summarise(min=min(worktime, na.rm=T), max=max(worktime, na.rm=T), mean=mean(worktime))
```

iii. Brief summary 

###should i drop na for all variables?

Write a brief report to summarize all the variables collected. Include both summary statistics (including sample size) and graphical displays such as histograms or bar charts where appropriate. Comment on what you have found from this sample. (For example - it's very interesting to think about why would one work for a job that pays only 10cents/each survey? Who are those survey workers? The answer may be interesting even if it may not directly relate to our goal.)

Usable data was obtained from `r nrow(radio)` subjects. Of these, `r (sum(!complete.cases(radio))/n)*100`% of subject's data was incomplete (i.e. missing one or more demographic variables). Number of responses for each variable and final summary of data below:

``` {r summary, echo=FALSE}
#sample size for each variable
sapply(radio, function(x) sum(!is.na(x))) 
#summary of all data
sapply(radio, summary) 
```

Plots!

``` {r wharton.plot}
w<- ggplot(radio, aes(x=sirius, fill=wharton)) + geom_bar(stat="count") + scale_fill_brewer(palette="Blues")
w
```


``` {r education.plot}
d<- ggplot(radio) + geom_bar(aes(x=education), stat="count", fill="darkblue") + theme(axis.text.x = element_text(angle = 60, hjust=1)) + ggtitle("Reported education of survey respondents") #should i drop NA before plotting?
d
```

``` {r income.plot}
i<- ggplot(radio, aes(x=income, fill=wharton)) + geom_bar(stat="count")
i
```

``` {r age.plot}
a <- ggplot(radio, aes(x=age, y = ..density..)) + geom_histogram(bins=25, color="white", fill= "darkblue" )
a
```

``` {r worktime.plot}
t <- ggplot(radio, aes(x=worktime, y = ..density..)) + geom_histogram(bins=25, color="white", fill= "darkgreen" )
t
```

## Sample properties

The population from which the sample is drawn determines where the results of our analysis can be applied or generalized. We include some basic demographic information for the purpose of identifying sample bias, if any exists. Combine our data and the general population distribution in age, gender and income to try to characterize our sample on hand.

i. Does this sample appear to be a random sample from the general population of the USA?
ii. Does this sample appear to be a random sample from the MTURK population?

Note: You can not provide evidence by simply looking at our data here. For example, you need to find distribution of education in our age group in US to see if the two groups match in distribution. You may need to gather some background information about the MTURK population to have a slight sense if this particular sample seem to a random sample from there... Please do not spend too much time gathering evidence. 

### Comparison to General Population
Data describing the demographics of the US general population was obtained from the 2014 American Community Survey, data available from the US Census Bureau [here](https://data.census.gov/cedsci/). 


### Comparison to MTURK Population
Data describing the demographics of MTURK workers in the US is from Moss et al and obtained [here](https://osf.io/w7e8p/?view_only=37f51a62db6144a2950646975887bac9). Data was collected in 2019.

scales are different....

``` {r}
mpop <- as.data.frame(read_sav("data/MTurkEthics_Study1_Data.sav")) #load mturk data
#names(mpop)
mpop <- mpop %>% select(age, Whatisyourgender, Whatisthehighestlevelofschoolyouhavecompletedorthehighestdegreey, Thinkingbackoverthelastyearwhatwasyourfamilysannualincomeincludi) %>% rename(gender=Whatisyourgender, education=Whatisthehighestlevelofschoolyouhavecompletedorthehighestdegreey, income=Thinkingbackoverthelastyearwhatwasyourfamilysannualincomeincludi) #subset and rename columns
mpop
```

## Final estimate

``` {r siruis, echo=FALSE}
#estimating listenership 
slisten <- sum(radio$sirius == "Yes") #num subj who listen to sirius xm
wlisten <- sum(radio$wharton == "Yes") #num subj who listen to wharton radio
p <- (wlisten/slisten) #proportion sirius listeners who listen to wharton
p*100 #percent subj listening to sirius who listen to wharton
```

The Wharton radio listenership comprised of approximately ***`r prettyNum(p*51.6*100000, big.mark = ",")` individuals*** in January 2014, assuming that the study sample's reported listening habits are representative of the general population.

The aim of the present study was to estimate the audience size of radio show Business Radio Powered by the Wharton School (Wharton Radio), available on Sirius Radio. Audience size was estimated by assessing the proportion of Sirius Radio listeners who reported listening to the Wharton talk show. Data was collected via survey on Amazon's Mechanical Turk (MTurk) platform in May 2014. Of `r n` survey respondents, `r prettyNum(wlisten, big.mark = ",")` of  `r prettyNum(slisten, big.mark = ",")` Sirius Radio listeners reported listening to Wharton radio. This ratio was extrapolated to the approximately 51.6 million Sirius listeners in 2014, resulting in an estimated `r prettyNum(p*51.6*100000, big.mark = ",")` listeners to Wharton radio. This finding is limited by sampling methodology, which was restricted to individuals enrolled in MTurk and may not be representative of Sirius Radio listeners. 


## New task

Now suppose you are asked to design a study to estimate the audience size of Wharton Business Radio Show as of today: You are given a budget of $1000. You need to present your findings in two months. 

Write a proposal for this study which includes:

1. Method proposed to estimate the audience size.
2. What data should be collected and where it should be sourced from.
Please fill in the google form to list your platform where surveys will be launched and collected [HERE](https://forms.gle/8SmjFQ1tpqr6c4sa8) 

A good proposal will give an accurate estimation with the least amount of money used. 





# Case study 2: Women in Science


Are women underrepresented in science in general? How does gender relate to the type of educational degree pursued? Does the number of higher degrees increase over the years? In an attempt to answer these questions, we assembled a data set (`WomenData_06_16.xlsx`) from [NSF](https://ncses.nsf.gov/pubs/nsf19304/digest/field-of-degree-women) about various degrees granted in the U.S. from 2006 to 2016. It contains the following variables: Field (Non-science-engineering (`Non-S&E`) and sciences (`Computer sciences`, `Mathematics and statistics`, etc.)), Degree (`BS`, `MS`, `PhD`), Sex (`M`, `F`), Number of degrees granted, and Year.

Our goal is to answer the above questions only through EDA (Exploratory Data Analyses) without formal testing. We have provided sample R-codes in the appendix to help you if needed. 


## Data preparation  

1. Understand and clean the data

Notice the data came in as an Excel file. We need to use the package `readxl` and the function `read_excel()` to read the data `WomenData_06_16.xlsx` into R. 


i. Read the data into R.
ii. Clean the names of each variables. (Change variable names to  `Field`,`Degree`, `Sex`, `Year` and `Number` )
iii. Set the variable natures properly. 
iv. Any missing values?

2. Write a summary describing the data set provided here. 

i. How many fields are there in this data?
ii. What are the degree types? 
iii. How many year's statistics are being reported here? 



## BS degrees in 2015

Is there evidence that more males are in science-related fields vs `Non-S&E`? Provide summary statistics and a plot which shows the number of people by gender and by field. Write a brief summary to describe your findings.

## EDA bringing type of degree, field and gender in 2015

Describe the number of people by type of degree, field, and gender. Do you see any evidence of gender effects over different types of degrees? Again, provide graphs to summarize your findings.

## EDA bring all variables 

In this last portion of the EDA, we ask you to provide evidence numerically and graphically: Do the number of  degrees change by gender, field, and time? 

## Women in Data Science

Finally, is there evidence showing that women are underrepresented in data science? Data science is an interdisciplinary field of computer science, math, and statistics. You may include year and/or degree.

## Final brief report

Summarize your findings focusing on answering the questions regarding if we see consistent patterns that more males pursue science-related fields. Any concerns with the data set? How could we improve on the study?

## Appendix

To help out, we have included some R-codes here as references. You should make your own chunks filled with texts going through each items listed above. Make sure to hide the unnecessary outputs/code etc. 

1. Clean data

```{r data wrangling, echo = FALSE, warning = FALSE}
# For the demonstration purpose, we show this R-chunk by taking echo=TRUE
# In your final report you should hide all the R-chunks to keep your report flowing well.
wsci <- read_excel("WomenData_06_16.xlsx")
names(wsci)
head(wsci)
#change names
wsci %<>% 
  rename(Field = 'Field and sex')
# set the field, degree and sex as factors
wsci %<>% 
  mutate( Field = as.factor(Field))
```


```{r, echo=FALSE}
# wsci %<>%
#   rename(Field = "Field and sex",
#          Number = "Degrees Awarded") %>%
#   mutate(Field = as.factor(Field),
#          Degree = as.factor(Degree),
#          Sex = as.factor(Sex))

```


2. A number of sample analyses 

```{r eval = FALSE, echo = FALSE}
wsci %>%  # to get the average number of ppl by gender
  group_by(Field, Sex) %>%
  summarise(deg = mean(Number))

wsci %>%
  filter(Year == 2007) %>%
  ggplot(aes(x = Field, y = Number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(Degree~., scales = "free_y") +
  theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
  ggtitle("Degrees granted across fields by degree and gender") 

wsci %>%
  mutate(SE = ifelse(Field!="Non-S&E" , "S&E", "Non-S&E")) %>%
  group_by(SE, Sex) %>%
  summarise(SE_number = sum(Number)) %>%
  ggplot(aes(x = SE, y = SE_number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme(axis.text.y = element_text(angle = 60)) +
  ggtitle("Degrees granted by S&E vs non-S&E by gender")

wsci %>%
  mutate(SE = ifelse(Field!="Non-S&E" , "S&E", "Non-S&E")) %>%
  group_by(SE, Sex, Year) %>%
  summarise(SE_number = sum(Number)) %>%
  group_by(SE, Year) %>%
  mutate(ratio = SE_number / sum(SE_number)) %>%
  filter(Sex == "Female") %>%
  ggplot(aes(x = Year, y = ratio, color = SE)) +
  geom_point() + geom_line() +
  ggtitle("Female proportion in SE/non-SE across year")

wsci %>%
  mutate(SE = ifelse(Field!="Non-S&E" , "S&E", "Non-S&E")) %>%
  group_by(SE, Sex, Year, Degree) %>%
  summarise(SE_number = sum(Number)) %>%
  group_by(SE, Year, Degree) %>%
  mutate(ratio = SE_number / sum(SE_number)) %>%
  filter(Sex == "Female") %>%
  ggplot(aes(x = Year, y = ratio, color = SE)) +
  geom_point() + geom_line() +
  facet_grid(~Degree)+
  ggtitle("Female proportion in SE/non-SE across year by degree")


wsci %>%
  mutate(SE = ifelse(Field!="Non-S&E" , "S&E", "Non-S&E")) %>%
  group_by(SE, Sex, Year, Degree) %>%
  summarise(SE_number = sum(Number)) %>%
  ggplot(aes(x = Year, y = SE_number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(SE~Degree, scales = "free_y") +
  ggtitle("Degrees granted by sex, degree and SE")


wsci %>%
  mutate(SE = ifelse(Field!="Non-S&E" , "S&E", "Non-S&E")) %>%
  group_by(SE, Sex, Year, Degree) %>%
  summarise(SE_number = sum(Number)) %>%
  ggplot(aes(x = Year, y = SE_number, fill = Sex)) +
  geom_bar(stat = "identity", position = "fill") +
  facet_grid(SE~Degree, scales = "free_y") +
  ggtitle("Degrees granted proportion by sex across degree and SE")


wsci %>%
  filter(Field %in% c("Computer sciences", "Mathematics and statistics")) %>%
  ggplot(aes(x = Year, y = Number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(Field~Degree, scales = "free_y") +
  ggtitle("Degrees granted pr option by sex across degree and SE")


wsci %>%
  ggplot(aes(x = Year, y = Number, fill = Sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(Field~Degree, scales = "free_y") +
  ggtitle("Degrees granted proportion by sex across degree and SE")
```




# Case study 3: Major League Baseball

We would like to explore how payroll affects performance among Major League Baseball teams. The data is prepared in two formats record payroll, winning numbers/percentage by team from 1998 to 2014. 

Here are the datasets:

-`MLPayData_Total.csv`: wide format
-`baseball.csv`: long format

Feel free to use either dataset to address the problems. 

## EDA: Relationship between payroll changes and performance

Payroll may relate to performance among ML Baseball teams. One possible argument is that what affects this year's performance is not this year's payroll, but the amount that payroll increased from last year. Let us look into this through EDA. 

Create increment in payroll

i. To describe the increment of payroll in each year there are several possible approaches. Take 2013 as an example:

    - option 1: diff: payroll_2013 - payroll_2012
    - option 2: log diff: log(payroll_2013) - log(payroll_2012)

Explain why the log difference is more appropriate in this setup.

ii. Create a new variable `diff_log=log(payroll_2013) - log(payroll_2012)`. Hint: use `dplyr::lag()` function.

iii. Create a long data table including: team, year, diff_log, win_pct


## Exploratory questions

i. Which five teams had highest increase in their payroll between years 2010 and 2014, inclusive?

ii. Between 2010 and 2014, inclusive, which team(s) "improved" the most? That is, had the biggest percentage gain in wins?


## Do log increases in payroll imply better performance? 

Is there evidence to support the hypothesis that higher increases in payroll on the log scale lead to increased performance?

Pick up a few statistics, accompanied with some data visualization, to support your answer. 

## Comparison

Which set of factors are better explaining performance? Yearly payroll or yearly increase in payroll? What criterion is being used? 






